---
title: "[Deep learning] Gradient Decent"
date: 2020-04-20
toc: true
toc_sticky: true
header:
  teaser: 
use_math: true
categories: python udacity study deeplearning ai nural network
---


*이 포스팅은 Udacity의 Bertelsmann Technology Scholarship을 정리한 자료입니다.*  


# Lession 1 With Squared Errors 

Gradient Decent에 대해서는 이미 다루었지만, 여기서는 좀 더 자세한 수리적 배경을 살펴보려고 합니다.


## 1) SSE (SUM of the Squared Error)

우리는 신경망에 사용할 최적의 weights를 찾고자 합니다. 그리고 이를 찾기 위해 error라는 것을 활용합니다.

일반적으로는 squared error(SSE)를 합산해 계산합니다.

![nn52]()

수식이 복잡해 보이겠지만, 말로 풀어서 설명해 보면 간단합니다.


실제 데이터의 값인 y와 예측 값인 $\widehat{y}$ 차이를 제곱해 모든 아웃풋 j만큼 반복합니다.

그리고 이 반복을 모든 데이터 포인트인 $\muμ$만큼 반복해 모든 error의 합을 구합니다.

SSE는 error를 제곱하기에 항상 양수이기 때문에 클 수록 모델의 성능이 낮다고 판단할 수 있습니다.

위의 식에서 예측값인  $\widehat{y}$은 아래와 같은 식에서 구할 수 있고, 이를 반영해 식을 바꾸면 다음과 같습니다.

![nn53]()

여기서 우리의 목표는 E를 최소화할 수 있는 weights값 $w_{ij}$를 구하는 것이고, 여기서 바로 Gradient Decent의 차례입니다.

Gradient Decent에 대해서 더 자세히 알고 시다면 Khan academy의 [이 강좌](https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/gradient-and-directional-derivatives/v/gradient)를 참고해 주세요.

Gradient는 기변기의 변화를 의미합니다. 이 변화를 알기 위해서는 함수 f(x)를 미분하면 x에서의 기술기를 알 수 있는 함수  f'(x)를 구할 수 있습니다. 

예를 들어  f(x) = $x^2$ 일 때, 이를 미분하면 f ′(x)=2x 입니다. x = 2고, 기울기는 4가 되는 것입니다.

![nn54]()

Gradient는 둘 이상의 변수에도 구할 수 있습니다. w1, w2를 바탕으로 표현한 gradient descent는 다음과 같습니다.

![nn55]()

하지만 이런 Gradient가 항상 최적의 weights를 보장하는 것은 아닙니다. 만약 local mimimum에 도달해 버린다면, 더 이상 알고리즘을 반복하지 않게 됩니다.

![nn56]()


## 2) Code

Weights는 다음과 같은 식을 통해 계산할 수 있습니다.

$\Delta w_{i} = \eta \delta x_{i}$

여기서 error term인 $\delta $는 다음과 같습니다.

$\delta = (y - \widehat{y})f'\left ( h \right ) = \left ( y - \widehat{y} \right )f'\left ( \sum w_{i}x_{i} \right )$

여기서 $\left ( y - \widehat{y} \right )$은 output error입니다. 

그리고 *f'(h)*는 activation function인 *f(h)*를 미분한 함수입니다. 이는 output gradient의 도함수입니다.


```python
# sigmoid function을 activation 함수로 정의합니다.
def sigmoid(x):
    return 1/(1+np.exp(-x))

# sigmoid function의 도하수를 정의합니다. 
def sigmoid_prime(x):
    return sigmoid(x) * (1 - sigmoid(x))

# Input data입니다.
x = np.array([0.1, 0.3])
# Target입티다.
y = 0.2
# weights값을 임의로 정합니다.
weights = np.array([-0.8, 0.5])

# weight step 방정식의 eta값인 learning rate를 정의합니다. 
learnrate = 0.5

# 예측 바엉식을 정의합니다.
h = x[0]*weights[0] + x[1]*weights[1]
# or h = np.dot(x, weights)

# 네트워크의 아웃풋입니다. (y-hat)
nn_output = sigmoid(h)

# 아웃풋의 에러를 계산합니다. (y - y-hat)
error = y - nn_output

# output gradient를 정의합니다. (f'(h))
output_grad = sigmoid_prime(h)

# error term입니다. (delta)
error_term = error * output_grad

# Gradient descent를 수행합니다. 
del_w = [ learnrate * error_term * x[0],
          learnrate * error_term * x[1]]
# 또는 del_w = learnrate * error_term * x
```

