---
title: "[Deep learning] Nural Networks (1) Introduction"
date: 2020-04-17
toc: true
toc_sticky: true
header:
  teaser: 
categories: python udacity study deeplearning ai nural network
---


*이 포스팅은 Udacity의 Bertelsmann Technology Scholarship을 정리한 자료입니다.*  


# Lesson 1 Nural Networks

딥러닝은 바둑가 같은 게임에서도 사용되고, 때로는 의사보다도 정확하기도 하며 최근에는 자율주행자동차로 각광받고 있습니다.

알파고 이후 인공지능하면 터미네이터의 스카이넷과 같은 상상을 하기 쉽지만, 실은 많은 신경망으로 이뤄진 분류기 입니다.

이 챕터에서 우리는 함께 Nural network가 무엇인지 살펴볼 것입니다. 


## 1) Classification Problems 

만약 우리가 대학교의 입학담당자라고 생각해 봅시다. 입학을 결정짓는 요인은 **두 가지**가 있습니다.

* 테스트 : 입학 시험에서 얼마나 높은 점수를 받았는지 나타내는 점수입니다.

* 학점 : 평소에 얼마나 좋은 학점을 받았는지 나타내는 점수입니다.

여기 A, B, C 세 명의 학생이 있습니다.

| 항목 | 테스트 | 학점 | 결과 |
|:---:|:----:|:----|:----|
| A | 9/10 | 8/10 | O |
| B | 3/10 | 4/10 | X |
| C | 7/10 | 6/10 | ? |

A는 합격되었고, B는 불합격되었습니다. 그렇다면 C는 합격일까요 아닐까요?

테스트와 학점, 두가지 데이터를 각각 축으로 하고, 다른 학생들의 데이터를 포함해 표현하면 다음과 같습니다.

![](https://drive.google.com/uc?id=1dhXe3oL45Ovvv6Chbut9SJOYixBPmH0e)

직관적으로 다음과 같은 선을 그어 합격 / 불합격 여부를 분류해 볼 수 있습니다. 정확히 분류되지 않는 친구들이 있지만, 일단은 무시합시다.

![](https://drive.google.com/uc?id=1plIqD2_ZzBsWoRKxkt8iKg2vSXP0stLT)

여기서 테스트를 x₁으로, 학점을 x₂로 놓게 되면, 다음과 같은 식을 얻을 수 있습니다.

> 2x₁+ x₂ - 18 = 0

x₁과 x₂를 넣어 0보다 크면 합격, -0보다 적으면 불합격으로 간주해 볼 수 있습니다.

식을 조금 더 일반화 해 보면, 

> w₁x₁ + w₂x₂ + b = 0 

> y = 1 if Wx + b ≥ 0

> y = 0 if Wx + b < 0

그런데 반에서 몇 등인지 등의 새로운 데이터가 포함된다면 어떨까요? 그렇다면 다음과 같이 3차원으로 표현할 수 있습니다.

> w₁x₁ + w₂x₂ +  w₃x₃ + b = 0

![](https://drive.google.com/uc?id=1vF2rMUqsX4dZ7mvT4zBFUQfu-7aDRIur) 


## 2) Perceptron

그럼 Nural Network를 만드는 블록인 Perceptron에 대해 알아보겠습니다.

![nn4](https://drive.google.com/uc?id=1c9rjQKN6wARgPOx2ypDORVfHC1oqRBBe)

위 그림과 같이 Perceptron은 데이터를 받아, 선형회귀식에 넣어서 classification 결과를 도출합니다. 

그런데 우리가 위에서 사용했던 식에는 -18 이라는 bias가 있었습니다. 이를 반영해 다시 보면 다음과 같습니다.

![nn5](https://drive.google.com/uc?id=1oXmmQc4exF0XoH5cqYRQXMwVDLHBPcrB)

그럼 여러개의 데이터가 들어간다면 어떻게 될까요? 지금까지 한 것을 일반화 하면,

![nn6](https://drive.google.com/uc?id=1gG_Y9V0Ge5Blwhj6MFiWtAZdfHwXHdHg)

이렇게 표현해 볼 수 있습니다. 여기서, bias를 의미하는 b는 위와 같이 별개의 input으로 볼 수도, 아니면 퍼셉트론 내에 정의할 수도 있습니다.

여기서 step function이란, 선형회귀의 결과물을 1 또는 0으로 만들어주는 함수를 의미합니다.

그런데 왜 Nural Network일까요? 이렇게 다양한 정보를 받아 결과물을 반환하는게, 우리의 신경망과 유사하기 때문입니다.

![nn7](https://drive.google.com/uc?id=1-LQCkm_IkEh7sbIsL2n3J-Df3IZhGbJV)


## 3) Perceptrons as Logical Operators : AND와 OR

우리는 퍼셉트론을 활용해 논리 연산자인 AND, OR, NOT과 XOR을 표현할 수도 있습니다.

먼저, **AND**의 경우를 살펴봅시다. 두 input이 모두 True 일 때 True를 반환해야 합니다.

![nn8](https://drive.google.com/uc?id=1JoX8PSQvBjRiBZmh1fGRWVZ1j_UYTZMF)

다음으로, **OR**를 살펴봅시다. 두 input중 적어도 하나가 True 일 때 True를 반환해야 합니다.

![nn9](https://drive.google.com/uc?id=1JgEErddSafCM-bzvPSlkhGpUl7eHcOmJ)

그런데, AND와 OR의 경우 형태가 아주 유사합니다. 둘의 차이는 bias인 b의 값 밖에 없습니다. 

코드를 통해 더 살펴보겠습니다.

```python
# AND 퍼셉트론을 테스트하는 코드입니다.
import pandas as pd

# weight1, weight2, bias를 설정합니다.
weight1 = 1.0
weight2 = 1.0
bias = -2.0

# Inputs 과 outputs입니다. 
test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]
correct_outputs = [False, False, False, True] #AND의 조건을 만족시키면 True로 출력합니다.
outputs = []

# outputs을 확인해 봅시다. 
for test_input, correct_output in zip(test_inputs, correct_outputs):
    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias
    output = int(linear_combination >= 0)
    is_correct_string = 'Yes' if output == correct_output else 'No'
    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])
	
# 아웃풋을 출력합니다. 
num_wrong = len([output[4] for output in outputs if output[4] == 'No'])
output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])
if not num_wrong:
    print('Nice!  You got it all correct.\n')
else:
    print('You got {} wrong.  Keep trying!\n'.format(num_wrong))
print(output_frame.to_string(index=False))

# 결과물은 다음과 같습니다.
# Nice!  You got it all correct.

# Input 1    Input 2    Linear Combination    Activation Output   Is Correct
#       0          0                  -2.0                    0          Yes
#       0          1                  -1.0                    0          Yes
#       1          0                  -1.0                    0          Yes
#       1          1                   0.0                    1          Yes
```

AND를 OR 퍼셉트론으로 바꾸려면 다음과 같은 두 가지 방법이 있습니다.

* weights 값을 높인다.
* bias의 절대값을 줄인다.


## 4) Perceptrons as Logical Operators : NOT

이번에는 **NOT**의 차례입니다. NOT은 input만 중요합니다. 실행결과가 0이면 1을, 1이면 0을 출력하고 다른 input은 무시합니다.

코드로 구현해 보겠습니다. 

```python
# NOT 퍼셉트론을 테스트하는 코드입니다.
import pandas as pd

# weight1, weight2, bias를 설정합니다.
weight1 = -1.0
weight2 = -2.0
bias = 1.0


# Inputs 과 outputs입니다. 
test_inputs = [(0, 0), (0, 1), (1, 0), (1, 1)]
correct_outputs = [True, False, True, False]
outputs = []

# outputs을 확인해 봅시다. 
for test_input, correct_output in zip(test_inputs, correct_outputs):
    linear_combination = weight1 * test_input[0] + weight2 * test_input[1] + bias
    output = int(linear_combination >= 0)
    is_correct_string = 'Yes' if output == correct_output else 'No'
    outputs.append([test_input[0], test_input[1], linear_combination, output, is_correct_string])

# 아웃풋을 출력합니다. 
num_wrong = len([output[4] for output in outputs if output[4] == 'No'])
output_frame = pd.DataFrame(outputs, columns=['Input 1', '  Input 2', '  Linear Combination', '  Activation Output', '  Is Correct'])
if not num_wrong:
    print('Nice!  You got it all correct.\n')
else:
    print('You got {} wrong.  Keep trying!\n'.format(num_wrong))
print(output_frame.to_string(index=False))

# 다음과 같은 결과가 출력됩니다.
# Nice!  You got it all correct.

# Input 1    Input 2    Linear Combination    Activation Output   Is Correct
#       0          0                   1.0                    1          Yes
#       0          1                  -1.0                    0          Yes
#       1          0                   0.0                    1          Yes
#       1          1                  -2.0                    0          Yes
```

## 5) Perceptrons as Logical Operators : XOR

사실 인공지능은 학계에서 제안된지 꽤나 오랜 세월이 지났습니다. 그러나 암흑기들이 있어 빛을 보지 못했는데요.

암흑기의 주연 중 하나인 XOR을 소개합니다. AND와 OR은 선형적으로 구분할 수 있고, NOT은 반전을 시키면 됩니다. 

XOR은 input의 값이 **다를** 때만 True를 반환하는 논리구조입니다. 아래 그림처럼 선형적이지 않습니다.

![nn10](https://drive.google.com/uc?id=1PpoDr4QFSobsBkQFoxX3rGsxQ97DmXYk)

이를 수학자들은 다층 퍼셉트론을 만듦으로서 해결해 버렸습니다. 아래 그림인데요 A, B, C를 직접 입력해 보세요.

![nn11](https://drive.google.com/uc?id=1cLmSaw9u6MfDWapTsSBwBHSZAGKARBwN)

그렇습니다. A에는 AND를, B에는 OR을, C에는 NOT을 넣으면(혹은 AND와 합켜 NAND) XOR이 구현됩니다!

어떻게 이런 생각을 다 했는지... 정말 대단합니다.