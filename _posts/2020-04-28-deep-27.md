---
title: "[Deep learning]CNN (1) MNIST dataset"
date: 2020-04-28
toc: true
toc_sticky: true
header:
  teaser: 
use_math: true
categories: python udacity study deeplearning ai nural network
---

*이 포스팅은 Udacity의 Bertelsmann Technology Scholarship을 정리한 자료입니다.*  

# Lesson 1 MNIST dataset

CNN은 딥러닝의 종류 중 하나로 다양한 영역에서 사용할 수 있습니다.

텍스트의 감성분석, 이미지 분류, 심지어는 게임을 하는 강화학습에서도 사용이 가능합니다.

한 때 전 세계를 들썩였던 알파고와 유사한 모델도 만들 수 있고, 드론에도 적용이 가능합니다. 

먼저 MNIST의 데이터를 기반으로 글씨를 데이터로 변환하는 작업을 수행해 보겠습니다.


## 1) Introduction


아마 CNN에서 가장 유명한 데이터셋 중 하나인 MNIST입니다. 

우리는 딥러닝을 통해 아래와 같은 구조로 분류해 주는 신경망을 구현하고자 합니다. 

![01](https://drive.google.com/uc?id=1UyMdaaLB1s11BIV7q6RRvl0vRNN_NUhP)

이 프로젝트에 대해 더 알고 싶으신 분들은 [NIPS](https://www.kaggle.com/benhamner/nips-papers)를 참고하시면 되겠습니다.

이 데이터셋에는 grayscale로 사람들이 수기로 쓴 숫자들이 존재합니다. 이를 컴퓨터가 읽게 하기 위해서 픽셀 단위로 나눠 볼 수 있습니다.

![02](https://drive.google.com/uc?id=1DYFDpUeB7Ysmh9eowX2MO0k2ABrvJSKR)

0-255사이의 값들을 [normalization](https://pytorch.org/docs/stable/torchvision/transforms.html#transforms-on-torch-tensor)하면 0에서 1 사이의 값으로 바꾸어 신경망 학습에 사용이 가능합니다.

또한 flattening작업을 통해 2x2의 형태였던 데이터를 하나의 벡터로 만들어 학습에 활용할 수 있습니다.

![03](https://drive.google.com/uc?id=1ENvVnPuYn25LHSY4WkDwFeMi2sbQrM6Q)


## 2) Structure

데이터의 수에 따라 784개의 entries가 생기고, output으로는 0에서 9까지 10개의 class가 있습니다.

이렇게 분류를 하기 위해 몇 개의 hidden layer가 필요할까요? 보통 선행 연구나 작업들을 참고해 이를 정하는 것이 적절합니다.

물론 학습을 통해 처음부터 완벽한 결과가 나오는 것은 아니기에 다음과 같은 방법들을 활용해야 합니다.

* Loss Function : 얼마나 잘못 분류되었는지를 확인합니다.

* Backpropagation : 어떤 weights가 잘못된 결과를 만들었는지 확인합니다.

* Optimization : 더 나은 weights를 계산하기 위해 최적화를 수행합니다.

이를 위해서 output layer에 soft max를 수행해 결과를 다음과 같이 해석가능하게 바꿀 수 있습니다.

![04](https://drive.google.com/uc?id=1BbghHAusBoozglu5G5Me0w0yttCsYztG)

이 결과값에 categorical cross-entropy loss를 계산할 수 있습니다. 

cross-entropy가 낮을 수록 아래와 같이 예측을 더 잘하는 모델이라고 생각할 수 있습니다.

![05](https://drive.google.com/uc?id=1E6r6lWQKE8I3RXvMIzJcYxAnaF2B72Yp)


## 3) Model Validation


이 과정에서 좋은 모델은 epoch가 반복되며 loss가 줄어듭니다.

![06](https://drive.google.com/uc?id=1KHS3z6jjShrJFD9MEX2qERgWJGr-l_UD)

하지만 어떻게 우리가 적정한 횟수의 epoch를 반복했다고 믿을 수 있을까요? 또 overfitting이 되고 있지 않다고 어떻게 확신할 수 있을까요?

이를 위해 Training Set을 Training과 validation으로 구분해 볼 수 있습니다.

validation을 수행함으로서 validation loss를 측정할 수 있고, 이를 바탕으로 model이 과적합 되는 것을 막을 수 있습니다.

![07](https://drive.google.com/uc?id=1nDZAjphObjRIGjNxOHqdVK0p97FBSDqa)


## 4) Process 

지금까지의 과정을 정리해 보면 다음과 같습니다.

이 과정을 통해 작성한 코드는 다음에 업데이트 해 두도록 하겠습니다. 

![08](https://drive.google.com/uc?id=1_-V8_o6PaFjzvtRhsaAo96WxPjoA7cEY)
