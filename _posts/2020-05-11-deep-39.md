---
title: "[Deep learning]Transfer Learning (2) Applying VGG16"
date: 2020-05-11
toc: true
toc_sticky: true
header:
  teaser: 
use_math: true
categories: python udacity study deeplearning ai nural network
---

#  Lesson 2 Applying Transfer Learning


아마 대부분의 사람들은 convolutional network 전체를 훈련시킬 자원을 가지고 있지 않을 것입니다. ImageNet같은 거대한 datasets을 활용한 신경망은 몇 개의 GPU를 활용해도 몇 주는 걸릴 수 있습니다.

> 새로 시작하는 대신에, 미리 훈련된 신경망을 feature를 뽑아내는 수단으로 활용하거나, fine tune에 활용하기 위해 사용할수 있습니다.

[ImageNet dataset](http://www.image-net.org/)을 훈련한 [VGGNet](https://arxiv.org/pdf/1409.1556.pdf)을 활용해 Transfer Learning을 해보고자 합니다. VGGNet은 convolutional와 maxpooling layers로 구성되어 있으며, 구조는 다음과 같습니다.

![cnn48](https://drive.google.com/uc?id=189vRU5gJunVitLa-BTsAAIBxGxmx47OO)

VGGNet은 단순한 구조를 가지고 있지만, 훌륭한 성능을 보여 ImageNet 대회에서 2등을 했었습니다. 아이디어는 간단합니다. 모든 convolutonal layer를 유지하되, **마지막 fully connected layer**를 새로운 classifier로 수정하는 것입니다. transfer learning에 대해서 더 알고 싶다면 다음 강의를 참고해 주세요. [the CS231n Stanford course notes](http://cs231n.github.io/transfer-learning/).

---

## 1) Download Data

<br>

VGGNet을 활용해 꽃을 분류하는 신경망을 만들어 보겠습니다. 먼저 사용할 library와 data를 부러오고, GPU에서 훈련이 가능한지 확인해 보겠습니다. 


```python
import os
import numpy as np
import torch

import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt

%matplotlib inline
```


```python
# CUDA를 사용할 수 있는지 확인해 봅니다. 
train_on_gpu = torch.cuda.is_available()

if not train_on_gpu:
    print('CUDA is not available.  Training on CPU ...')
else:
    print('CUDA is available!  Training on GPU ...')
```

    CUDA is available!  Training on GPU ...
    

## 2) Load and Transform our Data

PyTorch의 [ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder) class를 활용해 이미지를 손쉽게 불러오고자 합니다. 

```
root/class_1/xxx.png
root/class_1/xxy.png
root/class_1/xxz.png

root/class_2/123.png
root/class_2/nsdf3.png
root/class_2/asd932_.png
```


```python
# training과 test data directory를 설정합니다. 
data_dir = 'flower_photos/'
train_dir = os.path.join(data_dir, 'train/')
test_dir = os.path.join(data_dir, 'test/')

# classes를 정의합니다. 
classes = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']
```

VGG16은 `224`차원의 정사각형 이미지를 input으로 받습니다. transfer learning을 위해서 데이터를 이 모양으로 수정하는 것이 필요합니다.


```python
# load and transform data using ImageFolder를 활용해 data를 로드하고 변형시킵니다. 

# VGG-16에 적합하게 224x224 이미지로 변형시킵니다.
data_transform = transforms.Compose([transforms.RandomResizedCrop(224), 
                                      transforms.ToTensor()])

train_data = datasets.ImageFolder(train_dir, transform=data_transform)
test_data = datasets.ImageFolder(test_dir, transform=data_transform)

# data의 status를 확인해 보겠습니다. 
print('Num training images: ', len(train_data))
print('Num test images: ', len(test_data))
```

    Num training images:  3130
    Num test images:  540
    


```python
# dataloader의 parameters를 정의합니다.
batch_size = 20
num_workers=0

# data loaders를 준비합니다.
train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, 
                                           num_workers=num_workers, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, 
                                          num_workers=num_workers, shuffle=True)
```


```python
# sample data를 시각화해 보겠습니다. 

# training images 중 batch 하나를 가져와 보겠습니다. 
dataiter = iter(train_loader)
images, labels = dataiter.next()
images = images.numpy() # 이미지를 표시하기 위해 numpy로 변환합니다.

# 이미지와 라벨을 출력합니다.
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title(classes[labels[idx]])
```


![png](https://drive.google.com/uc?id=1V01k1GVkAoh0cklE94y3JXl9k5Aqx4rg)


---
## 3) Define the Model

모델을 정의하고 훈련하기 위해서 다음과 같은 작업을 수행합니다:
1. 훈련된 VGG16 model을 로드합니다. 
2. 모든 parameter를 "Freeze" 해, fixed feature extractor로 사용합니다.
3. 마지막 layer를 삭제합니다.
4. 새롭게 정의한 linear classifier를 연결합니다.


```python
# pytorch에서 훈련된 신경망을 불러옵니다.
vgg16 = models.vgg16(pretrained=True)

# 모델의 구조를 출력합니다. 
print(vgg16)
```

    Downloading: "https://download.pytorch.org/models/vgg16-397923af.pth" to /root/.torch/models/vgg16-397923af.pth
    100%|██████████| 553433881/553433881 [00:06<00:00, 79515896.00it/s]
    

    VGG(
      (features): Sequential(
        (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): ReLU(inplace)
        (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (3): ReLU(inplace)
        (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (6): ReLU(inplace)
        (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (8): ReLU(inplace)
        (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (11): ReLU(inplace)
        (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (13): ReLU(inplace)
        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (15): ReLU(inplace)
        (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (18): ReLU(inplace)
        (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (20): ReLU(inplace)
        (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (22): ReLU(inplace)
        (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
        (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (25): ReLU(inplace)
        (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (27): ReLU(inplace)
        (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (29): ReLU(inplace)
        (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      )
      (classifier): Sequential(
        (0): Linear(in_features=25088, out_features=4096, bias=True)
        (1): ReLU(inplace)
        (2): Dropout(p=0.5)
        (3): Linear(in_features=4096, out_features=4096, bias=True)
        (4): ReLU(inplace)
        (5): Dropout(p=0.5)
        (6): Linear(in_features=4096, out_features=1000, bias=True)
      )
    )
    


```python
print(vgg16.classifier[6].in_features) 
print(vgg16.classifier[6].out_features) 

```

    4096
    1000
    


```python
# 모든 "features" layer에 대해 parameter를 freeze시킵니다.
for param in vgg16.features.parameters():
    param.requires_grad = False
    
```

---
## 4) Final Classifier Layer

훈련된 feature extractor을 적용한 다음, 마지막 layer를 변경해야 합니다. 이 때 새로운 class의 개수와 같게 수정해야 합니다. 미리 훈련된 신경망에 이름을 입력하면 접근이 가능합니다. 예를 들어, `vgg16.classifier[6]`를 통해 이름이 "classifier" 6번째 layer를 불러올 수 있습니다.


```python
## n_inputs을 5개의 flower classes로 출력하는 fully connected layer로 정의해야 합니다.
## new layers automatically have requires_grad = True
import torch.nn as nn

n_inputs = vgg16.classifier[6].in_features

# 마지막 linear layer를 정의합니다. (n_inputs -> 5 flower classes)
# 새로운 layer는 자동으로 requires_grad = True가 됩니다.
last_layer = nn.Linear(n_inputs, len(classes))

vgg16.classifier[6] = last_layer

# GPU가 사용가능한지 확인해 사용합니다.
if train_on_gpu:
    vgg16.cuda()

# class의 개수와 같은지 확인해 보겠습니다.
print(vgg16.classifier[6].out_features)
#print(vgg16)
```

    5
    

## 5) [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) 과 [Optimizer](http://pytorch.org/docs/stable/optim.html)를 정의합니다. 

cross-entropy loss와 stochastic 작은 learning rate을 가진 gradient descent를 정의합니다. optimizer는 `vgg.classifier.parameters()`를 활용해 값을 받아올 수 있습니다. 


```python
import torch.optim as optim

# specify loss function (categorical cross-entropy)
criterion = nn.CrossEntropyLoss()

# specify optimizer (stochastic gradient descent) and learning rate = 0.001
optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)
```

---
## 6) Training

신경망을 훈련시킬 차례입니다.


```python
#  epochs를 정의합니다. 신경망을 훈련했기에, epochs를 2로 둡니다. 
n_epochs = 2

for epoch in range(1, n_epochs+1):

    # training과 validation loss를 기록합니다.
    train_loss = 0.0
    
    ###################
    # train the model #
    ###################
    # 모델을 훈련하기 위해 준비합니다.
    for batch_i, (data, target) in enumerate(train_loader):
        # CUDA가 사용 가능하면 GPU를 사용합니다.
        if train_on_gpu:
            data, target = data.cuda(), target.cuda()
        # 모든 optimized variables의 gradients를 재설정합니다.
        optimizer.zero_grad()
        # forward pass
        output = vgg16(data)
        # batch loss를 계산합니다. 
        loss = criterion(output, target)
        # backward pass
        loss.backward()
        # single optimization step을 수행합니다. (parameter를 업데이트합니다.)
        optimizer.step()
        # training loss를 업데이트합니다.
        train_loss += loss.item()
        
        if batch_i % 20 == 19:    # 특정 넘저의 mini-batche의 training loss를 출력합니다.
            print('Epoch %d, Batch %d loss: %.16f' %
                  (epoch, batch_i + 1, train_loss / 20))
            train_loss = 0.0
```

    Epoch 1, Batch 20 loss: 1.5694263100624084
    Epoch 1, Batch 40 loss: 1.3511997818946839
    Epoch 1, Batch 60 loss: 1.2522550106048584
    Epoch 1, Batch 80 loss: 1.1159413516521455
    Epoch 1, Batch 100 loss: 1.0367017894983293
    Epoch 1, Batch 120 loss: 0.9656843602657318
    Epoch 1, Batch 140 loss: 0.9590572088956832
    Epoch 2, Batch 20 loss: 0.8679903656244278
    Epoch 2, Batch 40 loss: 0.8232463061809540
    Epoch 2, Batch 60 loss: 0.8172291129827499
    Epoch 2, Batch 80 loss: 0.7619656682014465
    Epoch 2, Batch 100 loss: 0.7876206964254380
    Epoch 2, Batch 120 loss: 0.7264727443456650
    Epoch 2, Batch 140 loss: 0.7094496905803680
    

---
## 7) Testing

이제 꽃을 잘 분류하는 지 확인해 보겠습니다.


```python
# test loss를 5개의 class에 대해 측정합니다.
test_loss = 0.0
class_correct = list(0. for i in range(5))
class_total = list(0. for i in range(5))

vgg16.eval() 

# test data에 대해 적용합니다.
for data, target in test_loader:
    # CUDA가 사용가능하면 GPU를 사용합니다.
    if train_on_gpu:
        data, target = data.cuda(), target.cuda()
    # forward pass
    output = vgg16(data)
    # batch loss를 계산합니다.
    loss = criterion(output, target)
    # test loss를 업데이트합니다.
    test_loss += loss.item()*data.size(0)
    # output을 predicted class의 확률로 바꿔줍니다. 
    _, pred = torch.max(output, 1)    
    # predictions과 실제 값을 비교합니다.
    correct_tensor = pred.eq(target.data.view_as(pred))
    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())
    # 각 object class의 정확도를 업데이트합니다.
    for i in range(batch_size):
        label = target.data[i]
        class_correct[label] += correct[i].item()
        class_total[label] += 1

# test loss의 평균값을 계산합니다.
test_loss = test_loss/len(test_loader.dataset)
print('Test Loss: {:.6f}\n'.format(test_loss))

for i in range(5):
    if class_total[i] > 0:
        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (
            classes[i], 100 * class_correct[i] / class_total[i],
            np.sum(class_correct[i]), np.sum(class_total[i])))
    else:
        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))

print('\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (
    100. * np.sum(class_correct) / np.sum(class_total),
    np.sum(class_correct), np.sum(class_total)))
```

    Test Loss: 0.699897
    
    Test Accuracy of daisy: 79% (73/92)
    Test Accuracy of dandelion: 88% (117/132)
    Test Accuracy of roses: 62% (57/91)
    Test Accuracy of sunflowers: 76% (77/101)
    Test Accuracy of tulips: 74% (92/124)
    
    Test Accuracy (Overall): 77% (416/540)
    

## 8) Visualize Sample Test Results


```python
# batch를 하나 가져옵니다.
dataiter = iter(test_loader)
images, labels = dataiter.next()
images.numpy()

# CUDA를 쓸 수 있으면 GPU를 사용합니다.
if train_on_gpu:
    images = images.cuda()

# sample outputs을 가져옵니다.
output = vgg16(images)
# output probabilities를 predicted class로 변환합니다. 
_, preds_tensor = torch.max(output, 1)
preds = np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())

# 이미지와 라벨을 출력합니다. 
fig = plt.figure(figsize=(25, 4))
for idx in np.arange(20):
    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])
    plt.imshow(np.transpose(images[idx], (1, 2, 0)))
    ax.set_title("{} ({})".format(classes[preds[idx]], classes[labels[idx]]),
                 color=("green" if preds[idx]==labels[idx].item() else "red"))
```


![png](https://drive.google.com/uc?id=1Aw6Wuh0yRQIV6WW-yMSSIkZ8W-un3yWL)

