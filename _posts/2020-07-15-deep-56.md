---
title: "[Deep learning]Deploying a Model (2) Deployment"
date: 2020-07-15
toc: true
toc_sticky: true
header:
  teaser: 
use_math: true
categories: python udacity  study deeplearning ai nural network
---

#  Lesson 2 Deployment to Production

*이 포스팅은 Udacity의 Bertelsmann Technology Scholarship을 정리한 자료입니다.*  

## 1)Paths to Deployment

모델 배포는 쉽게 생각해 보면 machine learning모델을 기존 프로덕션 환경에 통합하는 것입니다. 

이를 통해 의사결정이나 예측을 수행할 수 있습니다. 따라서 모델링에서 배포를 할 때 담당자에게 model을 전해주는 것이 필요합니다.

이 과정에서는 모델이 python을 통해 작성되었다고 가정합니다. 

machine learning workflow에는 modeling component에서 deploment로 이어지는 데 사용할 수 있는 3가지 방법이 있습니다.

가장 일반적으로 사용하는 순서대로 논의해 보겠습니다. 여기서 세 번째 방법은 Amazon SageMaker 배포에서 사용된 것과 비슷합니다.

1. Python 모델은 프로덕션 환경의 프로그래밍언어로 *기록(record)*됩니다.

2. Python 모델은 PMML(Predictive Model Markup Language) 또는 PFA(Portable Format Analytics)로 *코딩*됩니다.

3. Python 모델은 프로덕션 환경에서 사용할 수 있는 형식으로 *변환(converted)*됩니다.

이제 하나씩 살펴보겠습니다.

**Python 모델을 프로덕션 환경의 프로그래밍언어로 기록(record)하기**

 가장 첫번째로 하게 되는 것은 python 모델을 JAVA나 C++ 등으로 변환하는 것입니다. 하지만 기존과 같은 모델을 다시 기록, 테스트 , 성능평가를 해야 하기 때문에 잘 사용되지 않습니다.
 
**모델을 PMML 또는 PFA로 코딩하기**

 두번째 방법은 PMML(Predictive Model Markup Language) 또는 PFA(Portable Format Analytics)로 *코딩*하는 것입니다.
 
예측 모델을 프로덕션 환경으로 deploment할 수 있는 표준 방법입니다. 개발자들은 PMML과 PFA를 개발하여 데이터 마이닝 및 machine learning에 사용하는

특정 예측 모델에 대해 공급자 중립적으로 실행할 수 있게 합니다. 특정 분석 소프트웨어를 사용하면 IBM SPSS, R, SAS Base&Enterprise Miner, Apache Spark,

Teradata Warehouser Miner, TIBCO Spotfire 등에서 PMML을 직접 가져올 수 있습니다.

**모델을 프로덕션 환경에서 사용할 수 있는 형식으로 변환하기**

 마지막 방법은 python 모델과 라이브러리와 매서드를 사용해 코드를 프로덕션 환경에서 사용할 수 있도록 벼노한하는 것입니다.
 
PyTorch, Tensorflow, Scikit-Learn과 같은 유명한 machine learning 소프트웨어는 Python model을 
 
ONNX([Open Neural Network Exchange](https://onnx.ai/))기본적인 포멧으로 변환하는 매서드가 있습니다.

* Python model을 deploment로 옮기는 가장 쉬운 방법입니다.

* model을 프로덕션 환경으로 옮기는 가장 일반적인 방법입니다.

* containers, endpoints 그리고 APIs(Applicationm Programming Interfaces)같은 기술들은 프로덕션 환경에 model을 쉽게 deploy하게 도와줍니다.
 

## 2) Machine Learning Workflow and Deployment


![004](https://drive.google.com/uc?id=1w0X9BQTQiojKVd6DBXymJnq4hu-YIBdd)
	 
 Machine Learning workflow를 보면 Exploring과 Processing Data가 Modeling과 밀접한 연결이 있음을 알 수 있습니다.

잘 준비된 데이터가 없다면 modeling을 할 수도 없습니다. 상대적으로 deploment는 데이터 modeling이나 processing 보다 프로덕션 환경과 밀접하게 연결되어 있습니다.

그렇기 때문에 일반적으로 deploment-운영-와 나머지 machine learning workflow-개발-사이에는 분리되는 지점이 있었습니다. 

과걱에는 일반적으로 분석가가 개발을, 프로덕션 환경을 담당하는 소프트웨어 개발자가 운영을 처리했습니다. 하지만 최근의 containers, endpoints, API 등의 개발로 인해

이런 구분이 약해졌습니다. 즉, 분석가가 deploment의 일부를 직접 처리해 모델에 대한 빠른 업데이트가 가능해 진 것입니다.

SageMaker 및 ML Engine과 같은 클라우드 서비스의 발전과 Containers 및 REST API와 같은 기술을 통해 분석가는 쉽게 deploment를 처리할 수 있게 되었습니다.