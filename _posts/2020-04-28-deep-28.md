---
title: "[Deep learning]CNN (2) MLP vs CNNs"
date: 2020-04-28
toc: true
toc_sticky: true
header:
  teaser: 
use_math: true
categories: python udacity study deeplearning ai nural network
---

*이 포스팅은 Udacity의 Bertelsmann Technology Scholarship을 정리한 자료입니다.*  

# Lesson 2 MLP vs CNNs

지난 시간에 MLP를 통해 이미지를 flattening하고 네트워크에 input하는 과정을 함께 보았습니다. 

당연하게도 MNIST에 대해서는 다양한 [해법](http://yann.lecun.com/exdb/mnist/)이 있습니다.

MNIST의 경우에는 모든 데이터의 size도 동일하고, 색도 없기에 MLP가 잘 작동하는 것 처럼 보입니다. 

하지만 이미지의 사이즈가 다르고, 전체 중 일부 장소에만 이미지가 등장하거나, 다양한 색이 있을 때는 어떻게 해야 할까요?

이때는 벡터로 변환할 필요 없이 행렬 자체를 input으로 넣을 수 있는 CNN이 더 좋은 성능을 보입니다. 

MLP와 CNN을 비교하면 다음과 같습니다. 

|MLP|CNN|
|---|---|
|fully conneted layer만 사용|Sparsely connected layer도 사용가능|
|Vector만을 input으로 사용 가능|행렬역시 input으로 사용 가능|

기존의 MLP에서, 모든 node는 hidden node에 input으로 사용됩니다.

![9](https://drive.google.com/uc?id=111kwjs6QyO_7cIauG_kZhuhfvalaQOzB)

그런데 굳이 이럴 필요가 있을까요? 만약 이미지를 4개의 영역으로 분할 해, input으로 사용한다면 어떨까요?

![10](https://drive.google.com/uc?id=141lst946oiCZdJTMJP7SJ6NmNoo2-YDH)

이런 아이디어에서 CNN(Convolutional Nural Network)가 디자인되었습니다. 

![11](https://drive.google.com/uc?id=1iz1Hfx9anp_NDqCwJea4UpiLHv8xTRQi)

CNN은 이미지에 다양한 filter를 적용해서 


## 1) Frequency in images
 
이미지의 intensity를 확인하기 위해서 픽셀의 밝기 등에 반영하는 filter를 사용합니다. 

이런 filter들을 통해 이미지의 경계를 파악하거나, 텍스처들을 구분할 수 있습니다. 

filter에 대해 알아보기 위해 frequency에 대해 살펴보겠습니다.

직관적으로 새가 지줘기는 소리나 바이올린 소리는 high frequency로, bass durm같은 것은 low frequency로 상상해 볼 수 있습니다.

소리에서 'frequency'는 일정한 사이클을 그리는 진동이라고 생각해 볼 수 있습니다.

![12](https://drive.google.com/uc?id=1zu0VYFvo4wKEg4PK47iDQhZPJ8mMwcDS)

이미지에서도 frequency란 **변화율**입니다. 이미지는 어디서 변화할까요? 바로 경계에서 많은 변화를 가지게 됩니다.

모든 이미지는 high와 low frequency를 모두 가지고 있습니다. High frequency는 또한 **이미지의 경계**를 나타냅니다. 

![13](https://drive.google.com/uc?id=1z0uxBRPmkUy9stGjV0lqRXosKM32O5qy)

이를 바탕으로 우리는 object들을 구분할 수 있습니다.


## 2) High-pass filter

이미지 프로세싱에서 필터는 두 가지 용도로 사용됩니다.

* 원하지 않는 정보량을 줄이는데 사용할 수 있습니다.

* 이미지의 일부 정보를 증폭해서 물체의 경계나 특징을 부각시킬 수 있습니다.

Hig-pass filter는 이미지를 선명하게 만들고, **high frequency**를 좀 더 강조합니다. 

![14](https://drive.google.com/uc?id=1k9lboGy_DU_nvPVtWcIvvlufiYm5d5CF)

이런 filter를 위해서 convolution kernel이라는 행렬을 활용합니다. 이런 filter는 보통 weights를 주지 않기 위해 모든 값의 합을 0으로 만들어야 합니다. 

그 뒤, 이미지의 각 부분에 대해서 이 커널을 적용해 edge를 탐색하게 됩니다.  

![15](https://drive.google.com/uc?id=1UDd2AwZcVDQDYsIYwcipy_3fNvuk6JW2)

이 작업을 하는 코드는 추후에 업로드하도록 하겠습니다.


## 3) The Importance of Filters

CNN은 object recognition과 image classification에 사용되는 딥러닝 모델입니다. 

기본적인 CNN의 구조는 아래와 같습니다.

![16](https://drive.google.com/uc?id=15OfAisu7hiEWvOrntwcuU2PUTIWS1-Eu)

Convolutional layer는 여러개의 convolutional kernel인 여러 이미지 필터를 사용합니다.

![17](https://drive.google.com/uc?id=1LPgju2LjWHiS_bdV1tsUZrjKGx4PvNTB)

위의 예시에서 볼 수 있듯이 4개의 다른 필터는 4개의 이미지를 출력하고, 이 이 이미지들을 쌓아 depth가 4인 convolutional layer를 만듦니다. 

![18](https://drive.google.com/uc?id=1FgLfgOaAT0NU1DVlGiDT7qyYJvalMI6r)

이런 과정을 간략화하면 다음과 같이 표현할 수 있습니다.

![19](https://drive.google.com/uc?id=11ffflni9ntjrioExjufIl6yC1xYXQWv5)


## 4) Padding and Pooling 

만약 convolutional kernel의 사이즈가 image와 맞지 않으면 어떻게 할까요?

이 때는 이미지에 '0'값을 지니는 임의의 픽셀을 추가함으로서 해결할 수 있습니다.

![20](https://drive.google.com/uc?id=1NRM1wtqgh20lnWiMKhE9JN4yg0sJWpLl)

이렇게 추출된 convolution layer에 대해 Pooling을 함으로서 이미지의 주요한 특징들을 잡아낼 수 있습니다.